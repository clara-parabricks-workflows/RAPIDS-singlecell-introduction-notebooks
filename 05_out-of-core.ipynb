{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79e4dac4",
   "metadata": {},
   "source": [
    "# **Out-of-Core Single-Cell Analysis with RAPIDS-SingleCell & Dask**  \n",
    "**Author:** [Severin Dicks](https://github.com/Intron7)\n",
    "**Copyright** [scverse](https://scverse.org)\n",
    "\n",
    "In this notebook, we demonstrate the **out-of-core computation** capabilities of **rapids-singlecell** using **Dask**.  \n",
    "This approach allows us to analyze larger scale datasets, such as 1.3 million to **11 million cells** efficiently, even on relatively small hardware.  \n",
    "\n",
    "By leveraging **Dask**, we can:  \n",
    "- **Process large-scale single-cell datasets** without exceeding memory limits.  \n",
    "- **Enable chunk-based execution**, loading only the necessary data into memory at any time.  \n",
    "\n",
    "This method makes **large-scale single-cell analysis feasible** on standard hardware setups,  \n",
    "removing barriers to working with massive datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37588552-b9d5-4113-9f53-ecc63d3da815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask\n",
    "import time\n",
    "\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f159c97-e435-40c5-ac7b-aa37a6812ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rmm\n",
    "import cupy as cp\n",
    "\n",
    "from rmm.allocators.cupy import rmm_cupy_allocator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81da4d7",
   "metadata": {},
   "source": [
    "## **Initializing a Dask Cluster for Out-of-Core Computation**  \n",
    "\n",
    "To enable **out-of-core computation** and parallel processing,  \n",
    "we initialize a **Dask CUDA cluster**, which distributes computations across available GPU resources.  \n",
    "\n",
    "We create a **local GPU cluster** with the following configuration:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79faf22b-629e-43d6-a762-02dd1fa2e65c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 440 ms, sys: 85.4 ms, total: 525 ms\n",
      "Wall time: 2.64 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-5e1717aa-f828-11ef-886e-0242ac120002</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_cuda.LocalCUDACluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCUDACluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">fd752707</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 1\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 30\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 222.16 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "</tr>\n",
       "\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-fb842c9d-e925-4923-b116-45a72021c4c9</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://127.0.0.1:44487\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 1\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 30\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 222.16 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:38649\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 30\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:38711/status\" target=\"_blank\">http://127.0.0.1:38711/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 222.16 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:41455\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-8_chbdkm\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:44487' processes=1 threads=30, memory=222.16 GiB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cluster = LocalCUDACluster(CUDA_VISIBLE_DEVICES=\"0\", threads_per_worker=30)\n",
    "\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ac3268-f54b-40c6-9f56-6f0d942c6753",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import rapids_singlecell as rsc\n",
    "import anndata as ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94f7c9",
   "metadata": {},
   "source": [
    "## **Loading Large Datasets into AnnData with Dask**  \n",
    "\n",
    "To efficiently handle large-scale single-cell datasets, we load data directly from an **HDF5 (`h5`) or Zarr file**  \n",
    "into an **AnnData object** using **Dask arrays**. This enables **lazy loading**, allowing data to be processed in chunks  \n",
    "without exceeding memory limits.  \n",
    "\n",
    "We achieve this using **`read_elem_as_dask`**, which loads the expression matrix (`X`) as a **Dask array**\n",
    "\n",
    "Let's first download the data.  \n",
    "- For the 1.3M cells dataset, this may take about 5 minutes, as it is 5.3 gigabytes to download and convert.  This is the default dataset for running the notebook.\n",
    "- For the 11M cells dataset, downloading can get considerable time, as it is over 43GB of data to download and convert.  This dataset is commented out by default.  You will have to uncomment the links below, as instructed, to download this dataset.\n",
    "\n",
    "If you already have the data ready, it will skip the download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1308986-5fc0-47ec-97e3-565992d68229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./h5 directory found\n",
      "Downloading cell data into ./h5/cell_atlas.h5ad...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(output): \u001b[38;5;66;03m# Check to see if we have our final output.  If it is there, get to the analysis!\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownloading cell data into \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     \u001b[43mwget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m              \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dataset found\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/wget.py:526\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(url, out, bar)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    525\u001b[0m     binurl \u001b[38;5;241m=\u001b[39m url\n\u001b[0;32m--> 526\u001b[0m (tmpfile, headers) \u001b[38;5;241m=\u001b[39m \u001b[43mulib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinurl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmpfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m filename \u001b[38;5;241m=\u001b[39m detect_filename(url, out, headers)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outdir:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/urllib/request.py:268\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reporthook:\n\u001b[1;32m    266\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[0;32m--> 268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m block \u001b[38;5;241m:=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    269\u001b[0m     read \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(block)\n\u001b[1;32m    270\u001b[0m     tfp\u001b[38;5;241m.\u001b[39mwrite(block)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import os\n",
    "from anndata.experimental import read_elem_as_dask\n",
    "import h5py\n",
    "\n",
    "data_dir = \"./h5\"\n",
    "\n",
    "# 1.3M cells\n",
    "url = 'https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad'\n",
    "output = data_dir+'/nvidia_1.3M.h5ad'\n",
    "final = './zarr/nvidia_1.3M.zarr'\n",
    "\n",
    "# 11M Cells.  Please uncomment the 3 lines below to download this dataset\n",
    "# url = 'https://datasets.cellxgene.cziscience.com/3817734b-0f82-433b-8c38-55b214200fff.h5ad'\n",
    "# output = data_dir+'/cell_atlas.h5ad'\n",
    "# final = './zarr/cell_atlas.zarr'\n",
    "\n",
    "if not os.path.exists(final): # Check if zarr dataset directory exists\n",
    "    if not os.path.exists(data_dir): # Check if h5 directory exists\n",
    "        print('creating data directory')\n",
    "        os.system('mkdir ./h5')\n",
    "    else:\n",
    "        print(f'{data_dir} directory found')\n",
    "\n",
    "    if not os.path.isfile(output): # Check to see if we have our final output.  If it is there, get to the analysis!\n",
    "        print(f'Downloading cell data into {output}...')\n",
    "        wget.download(url, output)\n",
    "    else:\n",
    "        print(f'{output} dataset found')\n",
    "\n",
    "    # Start to convert the h5ad file to zarr\n",
    "    print(f'Converting {output} into {final}...')\n",
    "    SPARSE_CHUNK_SIZE = 20_000\n",
    "    \n",
    "    f = h5py.File(output)\n",
    "    X = f[\"X\"]\n",
    "    shape = X.attrs[\"shape\"]\n",
    "    adata = ad.AnnData(\n",
    "        X = read_elem_as_dask(X, (SPARSE_CHUNK_SIZE, shape[1])),\n",
    "        obs = ad.io.read_elem(f[\"obs\"]),\n",
    "        var = ad.io.read_elem(f[\"var\"]))\n",
    "    f.close()\n",
    "    \n",
    "    adata.write_zarr(final)\n",
    "    print(f'{final} is ready for use!')\n",
    "else:\n",
    "    print(f'{final} zarr dataset directory found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872bd56a-1766-46ea-a466-b79a136af90f",
   "metadata": {},
   "source": [
    "Now, let's read in the zarr data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc9a948-80ea-457f-8ded-151505a23418",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zarr\n",
    "\n",
    "SPARSE_CHUNK_SIZE = 20_000\n",
    "\n",
    "f = zarr.open(final)\n",
    "X = f[\"X\"]\n",
    "shape = X.attrs[\"shape\"]\n",
    "adata = ad.AnnData(\n",
    "    X = read_elem_as_dask(X, (SPARSE_CHUNK_SIZE, shape[1])),\n",
    "    obs = ad.io.read_elem(f[\"obs\"]),\n",
    "    var = ad.io.read_elem(f[\"var\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8246527-1102-4747-b328-939800567142",
   "metadata": {},
   "source": [
    "## **Transferring AnnData to GPU for Accelerated Computation**  \n",
    "\n",
    "Once the dataset is loaded as a **Dask-backed AnnData object**,  \n",
    "we transfer it to the **GPU** to leverage **RAPIDS-SingleCell’s** accelerated processing.  \n",
    "\n",
    "We use **`rsc.get.anndata_to_GPU()`**, which efficiently moves the AnnData object to GPU memory:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114352ef-3262-4103-a1a5-f9b33b712656",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsc.get.anndata_to_GPU(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2762631c-1b7d-49da-8bd4-3c9d5a0a0ef4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adata.X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c03b477-7b57-4ba9-895f-78c0a1ead5ff",
   "metadata": {},
   "source": [
    "## **Quality Control (QC) Metrics Calculation (Requires Synchronization)**  \n",
    "\n",
    "Before proceeding with further analysis, we compute **quality control (QC) metrics**  \n",
    "to assess dataset quality and filter out low-quality cells or genes.  \n",
    "\n",
    "We use **`rsc.pp.calculate_qc_metrics()`** to calculate key QC metrics\n",
    "\n",
    "Although we are working with Dask-backed AnnData, this operation requires a synchronization step.\n",
    "This means that Dask computations must be evaluated immediately,\n",
    "so the process is not completely lazy like other out-of-core operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4f2b47-d363-40c1-b168-cff95b084358",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rsc.pp.calculate_qc_metrics(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22daf379-e37e-46ed-91d8-53dbb6bc0563",
   "metadata": {},
   "source": [
    "## **Filtering Cells and Genes Without Additional Computation**  \n",
    "\n",
    "Instead of using **`sc.pp.filter_cells`** and **`sc.pp.filter_genes`**,  \n",
    "we apply filtering directly using boolean indexing to **avoid extra computation**.\n",
    "\n",
    "**Why Use Direct Indexing Instead of Built-in Functions?**\n",
    "* More Efficient with Dask → Avoids triggering additional computations.\n",
    "* Preserves Lazy Execution → Filtering is applied without forcing full dataset evaluation.\n",
    "* Copy is Essential → Using `.copy()` prevents views, which may not work reliably with Dask-backed AnnData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f90ad3-52ac-47da-8840-ccf9db43c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[(adata.obs[\"n_genes_by_counts\"]<=10000) \n",
    "            & (adata.obs[\"n_genes_by_counts\"]>=200)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299580e9-44a9-41c5-bfe2-570ddd61ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15ca8b-672b-40e2-bc64-4df3c977da83",
   "metadata": {},
   "source": [
    "## **Log Normalization (Fully Lazy Execution)**  \n",
    "\n",
    "Next, we apply **log normalization** to scale gene expression values.  \n",
    "This step ensures that differences in sequencing depth across cells do not dominate downstream analysis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe6f8f-9086-474b-9583-d85b9190593f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rsc.pp.normalize_total(adata,target_sum = 10000)\n",
    "rsc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03588f87-4603-46f6-aa9a-1f16f05f1ac6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Selecting Highly Variable Genes (Requires Synchronization)**  \n",
    "\n",
    "To focus on the most informative features, we identify **highly variable genes (HVGs)**  \n",
    "using the **Cell Ranger** method and subset the dataset accordingly.  \n",
    "\n",
    "**Important Considerations:**\n",
    "* Requires Synchronization → Computing highly variable genes triggers evaluation,\n",
    "meaning this step is not fully lazy when using Dask.\n",
    "* Copy is Essential → Using `.copy()` prevents views, ensuring the operation works properly with Dask-backed AnnData.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84f792-2b06-4bfa-8cca-3b4eaec042ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rsc.pp.highly_variable_genes(adata,n_top_genes=5000, flavor=\"cell_ranger\")\n",
    "adata = adata[:,adata.var.highly_variable].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c17487c-bd39-4cdd-9873-db2b8952efff",
   "metadata": {},
   "source": [
    "## **Scaling Gene Expression (Requires Synchronization)**  \n",
    "\n",
    "To standardize gene expression values, we apply **feature scaling**,  \n",
    "ensuring that all genes contribute equally to downstream analysis.\n",
    "\n",
    "**Important Considerations:**\n",
    "* Requires Synchronization → Since the input matrix is in CSR format (Compressed Sparse Row),\n",
    "this step forces an immediate computation, meaning it is not fully lazy like earlier transformations.\n",
    "* Scaling → Divides each gene’s expression values by its standard deviation.\n",
    "* zero_center=False → Keeps the scaled values non-centered,\n",
    "which is beneficial for sparse matrices and GPU acceleration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab10f1e1-2fe5-4f5d-aa9d-1357d2d55a49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rsc.pp.scale(adata, zero_center= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c116d8-05cf-4efb-a25d-726e0c0f6c3f",
   "metadata": {},
   "source": [
    "## **Principal Component Analysis (PCA) on GPU (Two-Step Synchronization Process)**  \n",
    "\n",
    "To reduce dimensionality while preserving meaningful variation,  \n",
    "we perform **Principal Component Analysis (PCA)** using **GPU acceleration**.\n",
    "\n",
    "Understanding the Two-Step Synchronization in PCA:\n",
    "1. Mandatory Synchronization for Covariance & Mean Calculation\n",
    "    * PCA requires computing the covariance matrix and mean vector,\n",
    "    which must be explicitly synchronized before proceeding.\n",
    "    * This step is handled automatically within `rsc.pp.pca()`.\n",
    "\n",
    "2. Finalizing the Transformation with `.compute()`\n",
    "    * After computing the principal components, the data remains lazy (Dask CuPy array).\n",
    "    * Calling `.compute()` on `adata.obsm[\"X_pca\"]` performs the final transformation,\n",
    "      projecting the data onto the computed PCs and materializing the result as a fully computed CuPy array.\n",
    "\n",
    "**Why This Matters?**\n",
    "* The first synchronization (**covariance & mean**) ensures the PCA model is ready.\n",
    "* The second synchronization (`compute()`) ensures that the transformed data is fully realized\n",
    "for downstream analyses like clustering and UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b525a19c-6ed6-4e2c-a249-c4fc536862bb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Dask Worker process (from Nanny):\n",
      "2025-03-03 12:10:11,062 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/asyncio/runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/asyncio/base_events.py\", line 687, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/distributed/nanny.py\", line 985, in run\n",
      "    await worker.finished()\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/distributed/core.py\", line 494, in finished\n",
      "    await self._event_finished.wait()\n",
      "  File \"/opt/conda/lib/python3.12/asyncio/locks.py\", line 212, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/distributed/process.py\", line 202, in _run\n",
      "    target(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/distributed/nanny.py\", line 1023, in _run\n",
      "    asyncio_run(run(), loop_factory=get_loop_factory())\n",
      "  File \"/opt/conda/lib/python3.12/asyncio/runners.py\", line 194, in run\n",
      "    return runner.run(main)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/asyncio/runners.py\", line 123, in run\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rsc.pp.pca(adata, n_comps = 100,mask_var=None)\n",
    "adata.obsm[\"X_pca\"]=adata.obsm[\"X_pca\"].compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
